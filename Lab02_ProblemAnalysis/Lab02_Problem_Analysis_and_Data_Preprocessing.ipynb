{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0WhpMgiS1o5A"
   },
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "The goal of this lab is to introduce you to data preprocessing techniques in order to make your data suitable for applying a learning algorithm.\n",
    "\n",
    "## 1. Handling Missing Values\n",
    "\n",
    "A common (and very unfortunate) data property is the ocurrence of missing and erroneous values in multiple features in datasets. For this exercise we will be using a data set about abalone snails.\n",
    "The data set is contained in the Zip file you downloaded from Moodle `abalone.csv`.\n",
    "\n",
    "To determine the age of a abalone snail you have to kill the snail and count the annual\n",
    "rings. You are told to estimate the age of a snail on the basis of the following attributes:\n",
    "1. type: male (0), female (1) and infant (2)\n",
    "2. length in mm\n",
    "3. width in mm\n",
    "4. height in mm\n",
    "5. total weight in grams\n",
    "6. weight of the meat in grams\n",
    "7. drained weight in grams\n",
    "8. weight of the shell in grams\n",
    "9. number of annual rings (number of rings +1, 5 yields age)\n",
    "\n",
    "However, the data is incomplete. Missing values are marked with −1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "aTRoZnye1o5D",
    "outputId": "3b2669b0-1ea1-46d6-b768-638722442986",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>total_weight</th>\n",
       "      <th>meat_weight</th>\n",
       "      <th>drained_weight</th>\n",
       "      <th>shell_weight</th>\n",
       "      <th>num_rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4171</th>\n",
       "      <td>1</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>0.2490</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4172</th>\n",
       "      <td>0</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>0.4390</td>\n",
       "      <td>0.2145</td>\n",
       "      <td>0.2605</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173</th>\n",
       "      <td>0</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.205</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>0.5255</td>\n",
       "      <td>0.2875</td>\n",
       "      <td>0.3080</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174</th>\n",
       "      <td>1</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.150</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>0.5310</td>\n",
       "      <td>0.2610</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>0</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.195</td>\n",
       "      <td>1.9485</td>\n",
       "      <td>0.9455</td>\n",
       "      <td>0.3765</td>\n",
       "      <td>0.4950</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      type  length  width  height  total_weight  meat_weight  drained_weight  \\\n",
       "4171     1   0.565  0.450   0.165        0.8870       0.3700          0.2390   \n",
       "4172     0   0.590  0.440   0.135        0.9660       0.4390          0.2145   \n",
       "4173     0   0.600  0.475   0.205        1.1760       0.5255          0.2875   \n",
       "4174     1   0.625  0.485   0.150       -1.0000       0.5310          0.2610   \n",
       "4175     0   0.710  0.555   0.195        1.9485       0.9455          0.3765   \n",
       "\n",
       "      shell_weight  num_rings  \n",
       "4171        0.2490         11  \n",
       "4172        0.2605         10  \n",
       "4173        0.3080          9  \n",
       "4174        0.2960         10  \n",
       "4175        0.4950         12  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# load data \n",
    "df = pd.read_csv(\"abalone.csv\") #Should this not work please use the csv that was part of the zip file.\n",
    "df.columns=['type','length','width','height','total_weight','meat_weight','drained_weight','shell_weight','num_rings']\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q_KMa47j1o5E"
   },
   "source": [
    "### Exercise 1.1\n",
    "\n",
    "Compute the mean of of each numeric column and the counts of each categorical column, excluding the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "-dCq2-NW1o5F"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The column length:\n",
      "mean:\n",
      "0.5236920039486673\n",
      "counts:\n",
      "4052\n",
      "\n",
      "The column width:\n",
      "mean:\n",
      "0.40795533070088846\n",
      "counts:\n",
      "4052\n",
      "\n",
      "The column height:\n",
      "mean:\n",
      "0.1396100691016782\n",
      "counts:\n",
      "4052\n",
      "\n",
      "The column total_weight:\n",
      "mean:\n",
      "0.8288428746928747\n",
      "counts:\n",
      "4070\n",
      "\n",
      "The column meat_weight:\n",
      "mean:\n",
      "0.35926265119723527\n",
      "counts:\n",
      "4051\n",
      "\n",
      "The column drained_weight:\n",
      "mean:\n",
      "0.1802485861814605\n",
      "counts:\n",
      "4067\n",
      "\n",
      "The column shell_weight:\n",
      "mean:\n",
      "0.23860444280805104\n",
      "counts:\n",
      "4074\n",
      "\n",
      "The column num_rings:\n",
      "mean:\n",
      "9.921756193279371\n",
      "counts:\n",
      "4077\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##################\n",
    "#INSERT CODE HERE#\n",
    "##################\n",
    "#print(df.describe())\n",
    "for column in df.columns:\n",
    "    if column != 'type':\n",
    "        print(f\"The column {column}:\")\n",
    "        print('mean:')\n",
    "        print(df[df[column] != -1][column].mean())\n",
    "        print('counts:')\n",
    "        print(df[df[column] != -1][column].count())\n",
    "        print('')\n",
    "#df[df['length'] != -1]['length'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3I0CjV2c1o5G"
   },
   "source": [
    "### Exercise 1.2\n",
    "\n",
    "Compute the median of each numeric column,  excluding the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "sw_28SAt1o5G"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The column length:\n",
      "median:\n",
      "0.545\n",
      "\n",
      "The column width:\n",
      "median:\n",
      "0.425\n",
      "\n",
      "The column height:\n",
      "median:\n",
      "0.14\n",
      "\n",
      "The column total_weight:\n",
      "median:\n",
      "0.80175\n",
      "\n",
      "The column meat_weight:\n",
      "median:\n",
      "0.336\n",
      "\n",
      "The column drained_weight:\n",
      "median:\n",
      "0.1705\n",
      "\n",
      "The column shell_weight:\n",
      "median:\n",
      "0.2335\n",
      "\n",
      "The column num_rings:\n",
      "median:\n",
      "9.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##################\n",
    "#INSERT CODE HERE#\n",
    "##################\n",
    "for column in df.columns:\n",
    "    if column != 'type':\n",
    "        print(f\"The column {column}:\")\n",
    "        print('median:')\n",
    "        print(df[df[column] != -1][column].median())\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DMltOlp_1o5G"
   },
   "source": [
    "### Exercise 1.3\n",
    "\n",
    "Handle the missing values in a way that you find suitable. Think about different ways. Discuss dis-/advantages of your approach. Argue your choices.\n",
    "streichen von entweder Spalte oder Zeile\n",
    "oder lineare Regression\n",
    "oder die Werte mit den Mittelwert ersetzen von den jeweiligen Klassen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gxDCHrb31o5G"
   },
   "outputs": [],
   "source": [
    "##################\n",
    "#INSERT CODE HERE#\n",
    "##################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VpklBouL1o5H"
   },
   "source": [
    "### Exercise 1.4\n",
    "\n",
    "Perform Z-score normalization on every column (except the type of course!)\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "{\\color{Lavender}x}^{\\text{new}} = \\frac{{\\color{Lavender}x}-{\\color{CornflowerBlue}\\mu}_{\\color{VioletRed}x}}{{\\color{CornflowerBlue}\\sigma}_{\\color{VioletRed}x}}\n",
    "\\end{align}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "HbkY--hk1o5I"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   type  length  width  height  total_weight  meat_weight  drained_weight  \\\n",
      "0   0.0   0.350  0.265   0.090        0.2255       0.0995          0.0485   \n",
      "1   1.0   0.530  0.420   0.135        0.6770       0.2565          0.1415   \n",
      "2   0.0   0.440  0.365   0.125        0.5160       0.2155          0.1140   \n",
      "3   2.0     NaN  0.255   0.080        0.2050       0.0895          0.0395   \n",
      "4   2.0   0.425  0.300   0.095        0.3515       0.1410          0.0775   \n",
      "\n",
      "   shell_weight  num_rings  \n",
      "0         0.070        NaN  \n",
      "1         0.210        9.0  \n",
      "2         0.155       10.0  \n",
      "3         0.055        7.0  \n",
      "4         0.120        8.0  \n"
     ]
    }
   ],
   "source": [
    "##################\n",
    "#INSERT CODE HERE#\n",
    "##################\n",
    "#df['length'][1]\n",
    "df_copy = df.copy()\n",
    "for i in df:\n",
    "    df_mean=df[df[column] != -1][column].mean()\n",
    "    df_var=df[df[column] != -1][column].var()\n",
    "    if i != 'type':\n",
    "        df[i]=(df[i]-df_mean)/(df_var)\n",
    "#for column in df.columns:\n",
    "    #df_mean=df[df[column] != -1][column].mean()\n",
    "    #df_var=df[df[column] != -1][column].var()\n",
    "    #if column != 'type':\n",
    "        #df_copy[column].map(lambda x: (x-df_mean)/(df_var))\n",
    "        #df_copy[df[column] != -1][column].map(lambda x: x*x)\n",
    "        #df_copy.map(lambda x: x**3)\n",
    "        #print(df_mean)\n",
    "#df_copy.map(lambda x: x*0, na_action='ignore')\n",
    "print(df_copy[df_copy != -1].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>total_weight</th>\n",
       "      <th>meat_weight</th>\n",
       "      <th>drained_weight</th>\n",
       "      <th>shell_weight</th>\n",
       "      <th>num_rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.3515</td>\n",
       "      <td>0.1410</td>\n",
       "      <td>0.0775</td>\n",
       "      <td>0.120</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type  length  width  height  total_weight  meat_weight  drained_weight  \\\n",
       "0   0.0   0.350  0.265   0.090        0.2255       0.0995          0.0485   \n",
       "1   1.0   0.530  0.420   0.135        0.6770       0.2565          0.1415   \n",
       "2   0.0   0.440  0.365   0.125        0.5160       0.2155          0.1140   \n",
       "3   2.0     NaN  0.255   0.080        0.2050       0.0895          0.0395   \n",
       "4   2.0   0.425  0.300   0.095        0.3515       0.1410          0.0775   \n",
       "\n",
       "   shell_weight  num_rings  \n",
       "0         0.070        NaN  \n",
       "1         0.210        9.0  \n",
       "2         0.155       10.0  \n",
       "3         0.055        7.0  \n",
       "4         0.120        8.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df_copy != -1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000</td>\n",
       "      <td>2.120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.356</td>\n",
       "      <td>4.567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       A      B\n",
       "0  1.000  2.120\n",
       "1  3.356  4.567"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.DataFrame([[1, 2.12], [3.356, 4.567]])\n",
    "test.columns=['A','B']\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.494400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.262736</td>\n",
       "      <td>20.857489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           A          B\n",
       "0   1.000000   4.494400\n",
       "1  11.262736  20.857489"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.map(lambda x: x*x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "krOpdi_i1o5J"
   },
   "source": [
    "## 2. Preprocessing text (Optional)\n",
    "\n",
    "One possible way to transform text documents into vectors of numeric attributes is to use the TF-IDF representation. We will experiment with this representation using the 20 Newsgroup data set. The data set contains postings on 20 different topics. The classification problem is to decide which of the topics a posting falls into. Here, we will only consider postings about medicine and space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TmhZ8_FC1o5J"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index of each category is: [(0, 'sci.med'), (1, 'sci.space')]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "\n",
    "categories = ['sci.med', 'sci.space']\n",
    "raw_data = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)\n",
    "print(f'The index of each category is: {[(i,target) for i,target in enumerate(raw_data.target_names)]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3kWdpZz61o5K"
   },
   "source": [
    "Check out some of the postings, might find some funny ones!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "CFZgvye31o5K"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a sci.med email.\n",
      "\n",
      "There are 1187 emails.\n",
      "\n",
      "From: nyeda@cnsvax.uwec.edu (David Nye)\n",
      "Subject: Re: Migraines and scans\n",
      "Organization: University of Wisconsin Eau Claire\n",
      "Lines: 16\n",
      "\n",
      "[reply to geb@cs.pitt.edu (Gordon Banks)]\n",
      " \n",
      ">>If you can get away without ever ordering imaging for a patient with\n",
      ">>an obviously benign headache syndrome, I'd like to hear what your magic\n",
      ">>is.\n",
      " \n",
      ">I certainly can't always avoid it (unless I want to be rude, I suppose).\n",
      " \n",
      "I made a decision a while back that I will not be bullied into getting\n",
      "studies like a CT or MRI when I don't think they are indicated.  If the\n",
      "patient won't accept my explanation of why I think the study would be a\n",
      "waste of time and money, I suggest a second opinion.\n",
      " \n",
      "David Nye (nyeda@cnsvax.uwec.edu).  Midelfort Clinic, Eau Claire WI\n",
      "This is patently absurd; but whoever wishes to become a philosopher\n",
      "must learn not to be frightened by absurdities. -- Bertrand Russell\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "idx = np.random.randint(0, len(raw_data.data))\n",
    "print (f'This is a {raw_data.target_names[raw_data.target[idx]]} email.\\n')\n",
    "print (f'There are {len(raw_data.data)} emails.\\n')\n",
    "print(raw_data.data[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ytNRgBtD1o5L"
   },
   "source": [
    "Lets pick the first 10 postings from each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7XjYd0ML1o5L"
   },
   "outputs": [],
   "source": [
    "idxs_med = np.flatnonzero(raw_data.target == 0)\n",
    "idxs_space = np.flatnonzero(raw_data.target == 1)\n",
    "idxs = np.concatenate([idxs_med[:10],idxs_space[:10]])\n",
    "data = np.array(raw_data.data)\n",
    "data = data[idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tY4YffVy1o5M"
   },
   "source": [
    "<a href=\"http://www.nltk.org/\">NLTK</a> is a toolkit for natural language processing. Take some time to install it and go through this <a href=\"http://www.slideshare.net/japerk/nltk-in-20-minutes\">short tutorial/presentation</a>. (or use e.g. Google colab where the package is prepared already)\n",
    "\n",
    "The downloaded package below is a tokenizer that divides a text into a list of sentences, by using an unsupervised algorithm to build a model for abbreviation words, collocations, and words that start sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GhpnijnB1o5M"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import itertools\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Tokenize the sentences into words\n",
    "tokenized_sentences = [nltk.word_tokenize(sent) for sent in data]\n",
    "vocabulary_size = 1000\n",
    "unknown_token = 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LvKCOBjx1o5M"
   },
   "outputs": [],
   "source": [
    "# Count the word frequencies\n",
    "word_freq = nltk.FreqDist(itertools.chain(*tokenized_sentences))\n",
    "print (f\"Found {len(word_freq.items())} unique words tokens.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yw_h_8Vo1o5N"
   },
   "outputs": [],
   "source": [
    "# Get the most common words and build index_to_word and word_to_index vectors\n",
    "vocab = word_freq.most_common(vocabulary_size-1)\n",
    "index_to_word = [x[0] for x in vocab]\n",
    "index_to_word.append(unknown_token)\n",
    "word_to_index = dict([(w,i) for i,w in enumerate(index_to_word)])\n",
    " \n",
    "print (f\"Using vocabulary size {vocabulary_size}.\" )\n",
    "print (f\"The least frequent word in our vocabulary is '{vocab[-1][0]}' and appeared {vocab[-1][1]} times.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0CxBYzBs1o5N"
   },
   "source": [
    "### Exercise 2.1\n",
    "\n",
    "Code your own TF-IDF representation function and use it on this dataset. (Don't use code from libraries. Build your own function with Numpy/Pandas). Use the formular TFIDF = TF * (IDF+1). The effect of adding “1” to the idf in the equation above is that terms with zero idf, i.e., terms that occur in all documents in a training set, will not be entirely ignored. The term frequency is the raw count of a term in a document. The inverse document frequency is the natural logarithm of the inverse fraction of the documents that contain the word.\n",
    "\n",
    "Für die Berechnung der Ähnlichkeit wird aus dem tfidf Array aus jeder Spalte ein Vektor gemacht und die Vektoren werden mittels skalarprodukt bzw Winkelberechnung voneinander unterschieden. Je größer der Winkel desto größer der Unterschied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LAQX0zw11o5N"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "countvec = CountVectorizer()\n",
    "df = pd.DataFrame(countvec.fit_transform(data).toarray(), columns=countvec.get_feature_names_out())\n",
    "\n",
    "def tfidf(df):\n",
    "    \n",
    "    ##################\n",
    "    #INSERT CODE HERE#\n",
    "    ##################\n",
    "    return None\n",
    "    \n",
    "    \n",
    "rep = tfidf(df)\n",
    "\n",
    "# Check if your implementation is correct\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(norm=None, smooth_idf=False, use_idf=True)\n",
    "X_train = pd.DataFrame(vectorizer.fit_transform(data).toarray(), columns=countvec.get_feature_names_out())\n",
    "answer=['No','Yes']\n",
    "epsilon = 0.0001\n",
    "if rep is None: \n",
    "  print (f'Is this implementation correct?\\nAnswer: {answer[0]}')\n",
    "if rep is not None:\n",
    "  print (f'Is this implementation correct?\\nAnswer: {answer[1*np.all((X_train - rep) < epsilon)]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yvgshAez8XY2"
   },
   "outputs": [],
   "source": [
    "# an example of what to do with these similarities:\n",
    "\n",
    "\n",
    "# analysis with tf-idf\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similiarities = cosine_similarity(rep, rep) # measure of the similarity of the direction of two vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "39RjLr9J8b8f"
   },
   "outputs": [],
   "source": [
    "np.fill_diagonal(similiarities, 0)\n",
    "max_ind = np.unravel_index(similiarities.argmax(), similiarities.shape)\n",
    "similiarities[max_ind] # highest similarity of two documents"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Problem_Analysis_and_Data_Preprocessing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
